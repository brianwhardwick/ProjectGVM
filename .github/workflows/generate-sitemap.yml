name: Auto-SEO & Sitemap

on:
  # Trigger 1: Run automatically when you push HTML changes
  push:
    branches:
      - main
    paths:
      - '**/*.html'
      - '**/*.pdf'

  # Trigger 2: Manual Button (To force-update/fix all files)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  seo_and_sitemap:
    runs-on: ubuntu-latest
    name: Safe SEO Updates & Sitemap

    steps:
      - name: Checkout the repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # --- Step 1: Determine files to process ---
      - name: Get Files to Process
        id: target
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "Manual Run: Processing ALL HTML files."
            # Find all HTML files, exclude .git, replace newlines with spaces
            ALL_FILES=$(find . -name "*.html" -not -path "./.git/*" | tr '\n' ' ')
            echo "list=$ALL_FILES" >> $GITHUB_OUTPUT
            echo "run=true" >> $GITHUB_OUTPUT
          else
            echo "Push detected: checking for changes..."
            # We will rely on the next step for changed files
          fi

      - name: Get changed files (Push Only)
        if: github.event_name == 'push'
        id: changed-files
        uses: tj-actions/changed-files@v44
        with:
          files: |
            **.html

      - name: Combine File Lists
        id: final_list
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
             echo "files=${{ steps.target.outputs.list }}" >> $GITHUB_OUTPUT
          elif [ "${{ steps.changed-files.outputs.any_changed }}" == "true" ]; then
             echo "files=${{ steps.changed-files.outputs.all_changed_files }}" >> $GITHUB_OUTPUT
          else
             echo "files=" >> $GITHUB_OUTPUT
          fi

      # --- Step 2: Run The Fixed Python Script ---
      - name: Run Safe SEO Script
        if: steps.final_list.outputs.files != ''
        run: |
          python3 -c "
          import os
          import re
          import json
          from datetime import datetime

          # --- CONFIGURATION ---
          BASE_URL = 'https://www.projectgvm.com.au'
          file_list_str = '${{ steps.final_list.outputs.files }}'
          target_files = file_list_str.split(' ')
          TODAY = datetime.now().strftime('%Y-%m-%d')

          def update_meta_tag(content, property_name, new_value, is_name=False):
              attr = 'name' if is_name else 'property'
              safe_val = new_value.replace('\"', '&quot;')
              pattern = re.compile(f'(<meta\\s+{attr}=\"{property_name}\"\\s+content=\")(.*?)(\")', re.IGNORECASE)
              if pattern.search(content):
                  return pattern.sub(f'\\g<1>{safe_val}\\g<3>', content)
              return content

          def process_file(file_path):
              if not file_path or not os.path.exists(file_path): return
              
              print(f'Processing: {file_path}')
              with open(file_path, 'r', encoding='utf-8') as f:
                  original_content = f.read()

              content = original_content

              # 1. UPDATE SCHEMA DATES
              content = re.sub(r'(\"dateModified\": \")(\d{4}-\d{2}-\d{2})(\")', f'\\g<1>{TODAY}\\g<3>', content)

              # 2. SYNC TITLE TO META TAGS
              title_match = re.search(r'<title>(.*?)</title>', content, re.IGNORECASE)
              if title_match:
                  page_title = title_match.group(1)
                  content = update_meta_tag(content, 'og:title', page_title)
                  content = update_meta_tag(content, 'twitter:title', page_title, is_name=True)
                  # Update Schema Headline
                  content = re.sub(r'(\"headline\": \")(.*?)(\")', f'\\g<1>{page_title}\\g<3>', content)

              # 3. SYNC DESCRIPTION TO META TAGS
              desc_match = re.search(r'<meta\s+name=\"description\"\s+content=\"(.*?)\"', content, re.IGNORECASE)
              if desc_match:
                  page_desc = desc_match.group(1)
                  content = update_meta_tag(content, 'og:description', page_desc)
                  content = update_meta_tag(content, 'twitter:description', page_desc, is_name=True)
                  # Update Schema Description
                  content = re.sub(r'(\"description\": \")(.*?)(\")', f'\\g<1>{page_desc}\\g<3>', content)

              # 4. BREADCRUMBS & CANONICALS (Only for non-root files)
              if file_path.endswith('index.html') and file_path != 'index.html' and file_path != './index.html':
                  parts = os.path.dirname(file_path).replace('./', '').split('/')
                  parts = [p for p in parts if p] # Filter empty
                  
                  if parts:
                      rel_path = '/'.join(parts) + '/'
                      full_url = f'{BASE_URL}/{rel_path}'
                      
                      # Update Canonical
                      content = re.sub(r'(<link\s+rel=\"canonical\"\s+href=\")(.*?)(\")', f'\\g<1>{full_url}\\g<3>', content)
                      # Update Schema @id
                      content = re.sub(r'(\"@id\": \")(.*?)(\")', f'\\g<1>{full_url}\\g<3>', content)

                      # Generate Breadcrumb JSON
                      breadcrumbs = {
                          '@context': 'https://schema.org',
                          '@type': 'BreadcrumbList',
                          'itemListElement': []
                      }
                      breadcrumbs['itemListElement'].append({'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': f'{BASE_URL}/'})
                      
                      curr = ''
                      for i, part in enumerate(parts):
                          curr += part + '/'
                          name = part.replace('-', ' ').title()
                          if name.lower() == 'faq': name = 'FAQ'
                          if name.lower() == 'gvm gcm': name = 'GVM & GCM'
                          
                          breadcrumbs['itemListElement'].append({
                              '@type': 'ListItem', 
                              'position': i + 2, 
                              'name': name, 
                              'item': f'{BASE_URL}/{curr}'
                          })
                      
                      json_str = json.dumps(breadcrumbs, indent=2)
                      
                      # Use Markers to safely replace ONLY the breadcrumb block
                      bc_block = f'\n    <script type=\"application/ld+json\">\n{json_str}\n    </script>\n    '

                      # Regex to find EXISTING marker block
                      marker_pattern = re.compile(r'.*?', re.DOTALL)

                      if marker_pattern.search(content):
                          # Replace existing block
                          content = marker_pattern.sub(bc_block, content)
                      else:
                          # Append new block before closing head if it doesn't exist
                          content = content.replace('</head>', f'{bc_block}\n</head>')

              # 5. SAFETY CHECKS
              if '</head>' not in content:
                  print(f'SAFETY ERROR: </head> tag missing for {file_path}. Skipping.')
                  return
              if len(content) < (len(original_content) * 0.5):
                  print(f'SAFETY ERROR: Content shrank for {file_path}. Skipping.')
                  return

              # 6. WRITE FILE
              if content != original_content:
                  with open(file_path, 'w', encoding='utf-8') as f:
                      f.write(content)
                  print(f'Successfully updated {file_path}')

          # Run Loop
          for file in target_files:
              process_file(file.strip())
          "

      - name: Generate Sitemap
        uses: cicirello/generate-sitemap@v1
        with:
          base-url-path: 'https://www.projectgvm.com.au'
          exclude-paths: |
            /assets/
            404.html
            /css/
            /js/
            CNAME
            robots.txt
          path-to-root: .
          include-html: true
          include-pdf: true

      - name: Commit and Push Changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Auto-SEO: Safe Python Updates + Sitemap [skip ci]"
